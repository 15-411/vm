use std::str::FromStr;

use logos::{Logos, Lexer};

use crate::asm::{instr::TempID, reg::Register};


// TODO: Consider dynamic extensibility of lexer
// If we want to allow custom instructions, then we need to find some way
// to add onto the list of tokens. This might require using a custom solution
// instead of the Logos library.

/// List of Tokens to Lex For + Autogenerated Lexer
/// Check out the Logos Library for the Correct Syntax
/// https://github.com/maciejhirsz/logos.git
#[derive(Logos, Clone, Debug, PartialEq)]
pub enum Token {
  // Keywords
  #[token("ret")]   Ret,
  #[token("jmp")]   Jmp,
  #[token("cmp")]   Cmp,
  #[token("cmp86")] Cmp86,
  #[token("if")]    If,
  #[token("call")]  Call,
  #[token("phi")]   Phi,
  #[token("print")] Print,
  #[token("dump")]  Dump,
  #[token("nop")]   Nop,

  // Jump Keywords
  #[token("jz")]    Jz,
  #[token("jnz")]   Jnz,
  #[token("jne")]   Jne,
  #[token("je")]    Je,
  #[token("jl")]    Jl,
  #[token("jle")]   Jle,
  #[token("jg")]    Jg,
  #[token("jge")]   Jge,
  #[token("jnl")]   Jnl,
  #[token("jnle")]  Jnle,
  #[token("jng")]   Jng,
  #[token("jnge")]  Jnge,

  // Generally Used Tokens
  #[token("(")]    LParen,
  #[token(")")]    RParen,
  #[token(":")]    Colon,
  #[token("=")]    Assign,
  #[token(",")]    Comma,

  // Arithmetic Ops
  #[token("+")]    Add,
  #[token("-")]    Sub,
  #[token("*")]    Mul,
  #[token("/")]    Div,
  #[token("%")]    Mod,
  #[token("<<")]   LShift,
  #[token(">>")]   RShift,
  #[token(">>>")]   RShiftLog,

  // Comparsion Ops
  #[token("==")]   Eq,
  #[token("!=")]   Neq,
  #[token("<")]    Less,
  #[token("<=")]   Leq,
  #[token(">")]    Greater,
  #[token(">=")]   Geq,

  // Boolean Ops
  #[token("&")]    BitAnd,
  #[token("^")]    BitXor,
  #[token("|")]    BitOr,
  #[token("~")]    BitNot,
  #[token("&&")]   LogAnd,
  #[token("||")]   LogOr,
  #[token("!")]    LogNot,

  #[token("\n")]   NewLine,

  // Identifiers
  #[regex(r"\#(0|[1-9][0-9]*)", parse_temp)] 
  Temp(TempID),

  #[regex(r"@(0|[1-9][0-9]*)", parse_udec)] 
  Block(u64),

  #[regex(r"(-?)(0|[1-9][0-9]*)", parse_dec)]
  #[regex(r"0[xX][0-9a-fA-F]+", parse_hex)]
  Const(i32),

  #[regex(r"[a-zA-Z_][a-zA-Z0-9_]*", |lex| lex.slice().parse())] 
  Id(String),

  #[regex(r"[ \t\f\v\r]+", logos::skip)]
  #[regex(r"//[^\n]*", logos::skip)]
  #[error]
  Error,
}

/// Parse Temporaries into TempID Constituent
/// Including Numbered Temps and Register Temps
fn parse_temp(lex: &mut Lexer<Token>) -> Option<TempID> {
  let token = &lex.slice()[1..];

  Register::from_str(token).ok()
    .map(|x| TempID::Reg(x))
    .or_else(|| token.parse().ok().map(|x| TempID::Num(x)))
}


/// Parse Numeral Number Strings to i32 Integers
/// Must specially handle INT_MIN because the minus sign is ignored
fn parse_dec(lex: &mut Lexer<Token>) -> i32 {
  const INT_MIN: i64 = -2_147_483_648;
  const INT_MAX: i64 = 2_147_483_648;

  let res = match i64::from_str(lex.slice()) {
    Ok(val) if val >= INT_MIN && val <= INT_MAX => Some(val as i32),
    _ => None,
  };

  res.unwrap()
}

fn parse_hex(lex: &mut logos::Lexer<Token>) -> Option<i32> {
  // println!("LEX {:?}", lex.slice());

  fn preceding_zeros(string: &str) -> usize {
    for (i, chr) in string.char_indices() {
      if chr != '0' {
        return i;
      }
    }

    string.len()
  }

  let buffer = &lex.slice()[2..];
  if buffer.len() - preceding_zeros(buffer) > 8 {
    None
  } else {
    match i64::from_str_radix(&lex.slice()[2..], 16) {
      Ok(val) => Some(val as i32),
      Err(_) => None,
    }
  }
}


fn parse_udec(lex: &mut Lexer<Token>) -> Option<u64> {
  let slice = lex.slice();
  let n: u64 = slice[1..].parse().ok()?; // skip '#' or '@'
  Some(n)
}
